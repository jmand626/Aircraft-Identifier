{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Auto-detect the dataset path in Drive\n",
        "possible_paths = [\n",
        "    \"/content/drive/MyDrive/data/fgvc-aircraft-2013b\",  # Path from Notebook 1\n",
        "    \"/content/drive/MyDrive/fgvc-aircraft-2013b\"        # Path from Notebook 2\n",
        "]\n",
        "\n",
        "source_root = None\n",
        "for p in possible_paths:\n",
        "    if os.path.exists(p):\n",
        "        source_root = p\n",
        "        print(f\"‚úÖ Found dataset source at: {source_root}\")\n",
        "        break\n",
        "\n",
        "if source_root is None:\n",
        "    print(\"‚ùå CRITICAL ERROR: Could not find 'fgvc-aircraft-2013b' in Google Drive.\")\n",
        "    print(\"Please check if the folder is in 'MyDrive/data/' or just 'MyDrive/'.\")\n",
        "else:\n",
        "    # 2. Force Wipe Local Dirs (The \"Nuclear\" Option)\n",
        "    print(\"üßπ Wiping broken local directories...\")\n",
        "    if os.path.exists(\"/content/train\"): shutil.rmtree(\"/content/train\")\n",
        "    if os.path.exists(\"/content/test\"): shutil.rmtree(\"/content/test\")\n",
        "\n",
        "    # 3. Copy Fresh Data\n",
        "    print(f\"üìÇ Copying TRAIN data from {source_root}...\")\n",
        "    # We use full path copying to avoid nesting issues\n",
        "    os.system(f\"cp -r '{source_root}/train' '/content/'\")\n",
        "\n",
        "    print(f\"üìÇ Copying TEST data from {source_root}...\")\n",
        "    os.system(f\"cp -r '{source_root}/test' '/content/'\")\n",
        "\n",
        "    # 4. Cleanup Hidden Files (Crucial for ImageFolder)\n",
        "    print(\"üßπ Cleaning hidden files...\")\n",
        "    os.system('find /content/train -type d -name \".ipynb_checkpoints\" -exec rm -rf {} +')\n",
        "    os.system('find /content/test -type d -name \".ipynb_checkpoints\" -exec rm -rf {} +')\n",
        "\n",
        "    # 5. Final Verification\n",
        "    if os.path.exists(\"/content/train\"):\n",
        "        classes = [d for d in os.listdir(\"/content/train\") if os.path.isdir(f\"/content/train/{d}\")]\n",
        "        print(f\"\\nüéâ SUCCESS: Found {len(classes)} classes in /content/train\")\n",
        "        if len(classes) > 0:\n",
        "            print(f\"Example class: {classes[0]}\")\n",
        "            print(\"You can now run the DataLoader cell!\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è WARNING: Folder exists but contains 0 classes. Check Drive path.\")\n",
        "    else:\n",
        "        print(\"‚ùå ERROR: Copy failed completely.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzB9O6pWObw8",
        "outputId": "6a37f467-0483-4f86-a32c-d62b6e058c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found dataset source at: /content/drive/MyDrive/fgvc-aircraft-2013b\n",
            "üßπ Wiping broken local directories...\n",
            "üìÇ Copying TRAIN data from /content/drive/MyDrive/fgvc-aircraft-2013b...\n",
            "üìÇ Copying TEST data from /content/drive/MyDrive/fgvc-aircraft-2013b...\n",
            "üßπ Cleaning hidden files...\n",
            "\n",
            "üéâ SUCCESS: Found 100 classes in /content/train\n",
            "Example class: MD_80\n",
            "You can now run the DataLoader cell!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfhhC6QZOrM5",
        "outputId": "d5e110a2-2259-4825-8f0e-2f1740156c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "def verify_and_remove_images(directory):\n",
        "    print(f\"Scanning {directory} for corrupted images...\")\n",
        "    p = Path(directory)\n",
        "    # Get all .jpg and .jpeg files (case insensitive)\n",
        "    files = list(p.rglob(\"*.[jJ][pP][gG]\")) + list(p.rglob(\"*.[jJ][pP][eE][gG]\"))\n",
        "\n",
        "    corrupted_count = 0\n",
        "    for file_path in files:\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify() # Verify integrity\n",
        "        except (IOError, SyntaxError, Image.UnidentifiedImageError) as e:\n",
        "            print(f\"Bad file found: {file_path} - Removing...\")\n",
        "            os.remove(file_path)\n",
        "            corrupted_count += 1\n",
        "\n",
        "    print(f\"Scan complete. Removed {corrupted_count} corrupted images from {directory}.\\n\")\n",
        "\n",
        "# Run on both directories\n",
        "verify_and_remove_images(\"/content/train\")\n",
        "verify_and_remove_images(\"/content/test\")"
      ],
      "metadata": {
        "id": "7OfOeeJE9R7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0209f593-abb6-4a64-f9fc-af1ebd9dda95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning /content/train for corrupted images...\n",
            "Scan complete. Removed 0 corrupted images from /content/train.\n",
            "\n",
            "Scanning /content/test for corrupted images...\n",
            "Bad file found: /content/test/Gulfstream_V/1546282.jpg - Removing...\n",
            "Scan complete. Removed 1 corrupted images from /content/test.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "import setup_dataholders\n",
        "import importlib\n",
        "importlib.reload(setup_dataholders) # Ensure we have the latest version\n",
        "\n",
        "# Define Transforms (Standard ImageNet Normalization)\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create DataLoaders\n",
        "# Note: We are using workers=0 to avoid the deadlock issue you faced before\n",
        "train_dataloader, test_dataloader, class_names = setup_dataholders.create_dataloaders(\n",
        "    train_directory=local_train_dir,\n",
        "    test_directory=local_test_dir,\n",
        "    data_transforms=manual_transforms,\n",
        "    batch_size=32,\n",
        "    workers=0\n",
        ")\n",
        "\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "print(f\"Classes: {class_names[:10]}...\") # Print first 10"
      ],
      "metadata": {
        "id": "DztmO99YCc_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f6b15dc-1082-435c-be12-f81094d5fe06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 100\n",
            "Classes: ['707_320', '727_200', '737_200', '737_300', '737_400', '737_500', '737_600', '737_700', '737_800', '737_900']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# 1. Re-create the model (EfficientNet B0)\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_b0(weights=weights)\n",
        "\n",
        "# 2. FREEZE layers first (Feature Extraction)\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 3. Add the classifier head (with Dropout for regularization)\n",
        "torch.manual_seed(42)\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.3), # Increased dropout to prevent overfitting\n",
        "    nn.Linear(in_features=1280, out_features=100) # 100 classes\n",
        ")\n",
        "\n",
        "# 4. UNFREEZE the last 20% of the base model (The \"Fine-Tuning\" Magic)\n",
        "# This lets the model learn specific aircraft features like wing shapes\n",
        "for param in model.features[-3:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 5. Setup for Training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# Use a much lower learning rate for fine-tuning\n",
        "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1) # Helps with hard classes\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # 10x smaller learning rate\n",
        "\n",
        "# 6. Train!\n",
        "print(\"Starting Fine-Tuning...\")\n",
        "epochs = 15  # Needs more time to adjust\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\\n-------------------------------\")\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Training Loop\n",
        "    for batch, (X, y) in enumerate(train_dataloader): # Assumes train_dataloader exists\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_pred = model(X)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "    train_acc /= len(train_dataloader)\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "# 7. Save the Improved Model\n",
        "print(\"Saving improved model...\")\n",
        "torch.save(model.state_dict(), \"aircraft_model.pth\")\n",
        "from google.colab import files\n",
        "files.download(\"aircraft_model.pth\")"
      ],
      "metadata": {
        "id": "un2lt-osIVZ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "2dd57180-5507-45d6-aa48-c8bc697a99df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 141MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Fine-Tuning...\n",
            "Epoch 1/15\n",
            "-------------------------------\n",
            "Train Loss: 4.5499 | Train Acc: 0.0315\n",
            "Epoch 2/15\n",
            "-------------------------------\n",
            "Train Loss: 4.1651 | Train Acc: 0.1824\n",
            "Epoch 3/15\n",
            "-------------------------------\n",
            "Train Loss: 3.6168 | Train Acc: 0.3235\n",
            "Epoch 4/15\n",
            "-------------------------------\n",
            "Train Loss: 3.1441 | Train Acc: 0.4165\n",
            "Epoch 5/15\n",
            "-------------------------------\n",
            "Train Loss: 2.7271 | Train Acc: 0.5395\n",
            "Epoch 6/15\n",
            "-------------------------------\n",
            "Train Loss: 2.3981 | Train Acc: 0.6199\n",
            "Epoch 7/15\n",
            "-------------------------------\n",
            "Train Loss: 2.1161 | Train Acc: 0.7010\n",
            "Epoch 8/15\n",
            "-------------------------------\n",
            "Train Loss: 1.8979 | Train Acc: 0.7728\n",
            "Epoch 9/15\n",
            "-------------------------------\n",
            "Train Loss: 1.6964 | Train Acc: 0.8270\n",
            "Epoch 10/15\n",
            "-------------------------------\n",
            "Train Loss: 1.5321 | Train Acc: 0.8655\n",
            "Epoch 11/15\n",
            "-------------------------------\n",
            "Train Loss: 1.4248 | Train Acc: 0.8947\n",
            "Epoch 12/15\n",
            "-------------------------------\n",
            "Train Loss: 1.3210 | Train Acc: 0.9202\n",
            "Epoch 13/15\n",
            "-------------------------------\n",
            "Train Loss: 1.2322 | Train Acc: 0.9447\n",
            "Epoch 14/15\n",
            "-------------------------------\n",
            "Train Loss: 1.1882 | Train Acc: 0.9507\n",
            "Epoch 15/15\n",
            "-------------------------------\n",
            "Train Loss: 1.1296 | Train Acc: 0.9625\n",
            "Saving improved model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7fb46e3d-7f65-40b3-ab8b-fa28120e10b5\", \"aircraft_model.pth\", 16843569)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}